{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lezione 11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from liblet import Grammar, Derivation, cyk2table\n",
        "from L09 import cyk, to_cnf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simboli e input: stringhe e sequenze\n",
        "\n",
        "Un \"chiarimento\" dovuto sull'uso dei termini *simboli* e *input* e sulle relative scelte implementative adottate per il software prodotto per questo corso.\n",
        "\n",
        "In questi *handout*, i **simboli** (siano essi terminali che non) sono implementati come stringhe, che corrispondono al tipo [Text Sequence Type](https://docs.python.org/3.7/library/stdtypes.html#text-sequence-type-str) (brevemente `str`). Osservate che in Python *non esiste il tipo carattere*, pertanto anche quando i simboli sono composti da un'unica lettera, questi saranno di tipo `str`. \n",
        "\n",
        "Questo è evidente se, ad esempio, si ispeziona una `Grammar`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "G = Grammar.from_string(\"\"\"\n",
        "Name -> First Last\n",
        "First -> mario | franco\n",
        "Last -> bruni | rossi \n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'First', 'Last', 'Name'}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Sono stringhe (elementi di tipo str) i non terminali\n",
        "\n",
        "set(G.N)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bruni', 'franco', 'mario', 'rossi'}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ma pure i terminali!\n",
        "\n",
        "set(G.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In base alla definizione di **linguaggio**, le **parole** e le **forme sentenziali** sono sequenze di simboli (sugli opportuni alfabeti). Ragion per cui l'implementazione naturale di tali entità è fatta usando [liste](https://docs.python.org/3.7/tutorial/datastructures.html#more-on-lists) o [tuple](https://docs.python.org/3.7/tutorial/datastructures.html#tuples-and-sequences).\n",
        "\n",
        "Di nuovo, questo è evidente se, ad esempio, si ispeziona la forma sentenziale di una `Derivation`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('franco', 'rossi')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Derivation(G).leftmost((0, 2, 4)).sentential_form()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In linea di principio, quindi, l'*input* (termine informale) che, dei nostri algoritmi, è costituito da una *parola* (termine formale) deve essere una sequenza di simboli, quindi una lista o tupla.\n",
        "\n",
        "Non ha senso pensare all'*input* come a un elemento di tipo `str`, perché questo impedisce di riconoscere (in modo non \"ambiguo\") i simboli di cui è composto.\n",
        "\n",
        "Prestate attenzione alla diversità tra seguenti asserzioni:\n",
        "* `('franco', 'franco')` è una parola, ma non appartiene al linguaggio generato da `G`; \n",
        "* `'francofranco'` non sono non appartiene a tale linguaggio, ma non è nemmeno una parola sull'alfabeto `G.T` dal momento che, pur essendo un oggetto di tipo `str`, non è una sequenza di simboli terminali (contenuti in `G.T`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "G_cnf = to_cnf(G)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>td, th {border: 1pt solid lightgray !important ;}</style><table><tr><td style=\"text-align:left\"><pre>&nbsp;</pre></td><tr><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><tr><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><tr><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><tr><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><tr><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><tr><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><tr><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><tr><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><tr><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><tr><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><tr><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td><td style=\"text-align:left\"><pre>&nbsp;</pre></td></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 'francofranco' conduce ad una tabella di parsing \n",
        "# col numero errato di celle (dovrebbe essere 2 x 2)\n",
        "\n",
        "cyk2table(cyk(G_cnf, 'francofranco'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>td, th {border: 1pt solid lightgray !important ;}</style><table><tr><td style=\"text-align:left\"><pre>&nbsp;</pre></td><tr><td style=\"text-align:left\"><pre>First</pre></td><td style=\"text-align:left\"><pre>First</pre></td></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ()'franco', 'franco') conduce ad una tabella di parsing \n",
        "# 2 x 2 che nella cella più alta non ha il simbolo di partenza\n",
        "# dato che la parola non appartiene al linguaggio generato da G\n",
        "\n",
        "cyk2table(cyk(G_cnf, ('franco', 'franco')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>td, th {border: 1pt solid lightgray !important ;}</style><table><tr><td style=\"text-align:left\"><pre>Name</pre></td><tr><td style=\"text-align:left\"><pre>First</pre></td><td style=\"text-align:left\"><pre>Last</pre></td></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ()'franco', 'rossi') conduce ad una tabella di parsing \n",
        "# 2 x 2 che conferma il riconoscimento\n",
        "\n",
        "cyk2table(cyk(G_cnf, ('franco', 'rossi')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Se i simboli sono tutti lunghi uno?\n",
        "\n",
        "Può accadere (ed è accaduto senza che lo rendessi esplicito, cosa che può avervi indotti in confusione), che se i simboli terminali sono **tutti** stringhe di lunghezza uno, l'*input* possa essere \"impropriamente\" implementato, invece che con una lista di stringhe di lunghezza uno, come una stringa. \n",
        "\n",
        "Questa \"confusione\" tra i tipi è resa possibile dal fatto che in Python l'espressione `INPUT[i]` è legittima sia nel caso in cui `INPUT` si riferisca a una stringa, che a una lista o a una tupla; inoltre nel caso in cui i simboli siano stringhe di lunghezza uno, le due espressiono hanno lo stesso valore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'i'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# implementazione propria\n",
        "\n",
        "INPUT = ('p', 'i', 'p', 'p', 'o')\n",
        "\n",
        "INPUT[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'i'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# implementazione impropria\n",
        "\n",
        "INPUT = 'pippo'\n",
        "\n",
        "INPUT[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tokenizzazione e parsing\n",
        "\n",
        "La confusione si può fare ancora più acuta quando parliamo di *tokenizzazione*, oltre che di parsing.\n",
        "\n",
        "In tal caso ci sono due grammatiche (e quindi due linguaggi), in gioco.\n",
        "\n",
        "La prima grammatica $G_t = (N_t, T_t, P_t, S_t)$ è quella del **tokenizzatore**, è in generale una grammatica regolare i cui terminali $T_t$ sono i caratteri dell'alfabeto di macchina (ad esempio i caratteri *Unicode*). \n",
        "\n",
        "Tale grammatica può essere pensata come l'unione di $k>0$ grammatiche regolari $G^k_t = (N^k_t, T_t, P^k_t, S^k_t)$ (in cui gli $N^k_t$ e $P^k_t$ sono disgiunti e gli $S^k_t$ sono distinti al variare di $k$), ciascuna delle quali riconosce un certo \"tipo\" di *token*. $G_t$ è usualmente definita da $N_t =  \\{S_t\\} \\cup \\bigcup N^k_t$ e $P_t =  \\{S_t \\to ( S^1_t | S^2_t |  \\ldots | S^k_t )^* \\} \\cup \\bigcup P^k_t$ (dove la produzione per il simbolo iniziale, qui descritta con la notazione impropria delle espressioni regolari, indica che le parole $G_t$ sono sequenze di parole delle varie $G^k_t$, ossia di token.\n",
        "\n",
        "La seconda grammatica $G_p = (N_p, T_p, P_p, S_p)$ è quella del **parser**, è in generale una grammatica libera da contesto i cui terminali $T_p$ sono i simboli distinti delle grammatiche $G^k_t$, ossia $T_p = \\{S^1_t, S^2_t, \\ldots, S^k_t\\}$. \n",
        "\n",
        "Rispetto alla situazione in cui si considera solo il parsing, in questo contesto parlare di *input* può condurre ad ancor maggior confusione: tale termine può infatti riferirsi sia alla parola (in $T_t^*$) data in input al tokenizzatore, che alla parola (in $T_p^*$) da esso restituita che sarà quindi data in input al parser.\n",
        "\n",
        "### Un esempio\n",
        "\n",
        "Facciamo un esempio concreto, per cercare di chiarire meglio le idee. Supponiamo di voler scrivere una calcolatrice in grado di compiere operazioni aritmetiche su interi e veriabili, come ad esempio `52* pi`.\n",
        "\n",
        "Dapprima avremo bisogno di dividere l'espressione in token. Per farlo avremo bisogno di tre grammatiche regolari, una per gli interi: `Number -> [0-9]+`, una per le variabili `Var -> [a-z]+` e una per gli operatori `Op -> +|-|*|/` (i nostri tre tipi di token). Le metteremo assieme nella grammatica del tokenizzatore che avrà come prima produzione `S -> (' ' | Number | Var | Op)*` (osservate che c'è anche un \"trucco\" per buttare via gli spazi bianchi).\n",
        " \n",
        "Ora avremo bisogno di una grammatica libera da contesto per le espressioni: `Expr -> Expr Op Expr | Number | Var` (il cui unico non terminale è il simbolo iniziale `Expr`).\n",
        "\n",
        "Siamo pronti: dato l'input (`5`, `2`, `*`, ``` ```, `p`, `i`) sull'alfabeto Unicode, il tokenizzatore lo trasforma nell'input (`Number`, `Op`, `Var`) sull'alfabeto dei terminali del parser che quest'ultimo determinerà essere prodotto dalla derivazione leftmost `Expr -> Expr Op Expr | Number Op Expr -> Number Op Var`.\n",
        "\n",
        "Ora vi domanderete, qual è il valore dell'espressione? Questa è una ulteriore \"complicazione\". A ciascun *token* è associato un valore, che dipende dalla porzione di stringa che deriva (sull'alfabeto $T_t$). Ad esempio, il valore del primo token è 52, il valore del secondo è \"moltiplicazione\" mentre il valore del terzo e ultimo è `pi`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <span style=\"color: red\">Esercizi per casa</span>\n",
        "\n",
        "* Implementare tre funzioni che, dato un automa per $L_1$ e uno per $L_2$, costruiscano rispettivamente l'automa (non deterministico) per $L_1L_2$, $L_1\\cup  L_2$ e $L_1^*$.\n",
        "\n",
        "* Implementare una funzione per la costruzione dell'*automa completo* secondo l'algoritmo presentato nella Sezione 5.5; usatelo per scrivere una funzione che costruisca l'*automa complemento* per $L^C_1 = T^* - L_1$.\n",
        "\n",
        "* Implementate una funzione per la costruzione dell'*automa intersezione* per $L_1\\cap L_2$ secondo l'algoritmo presentato nella Sezione 5.5; provate a confrontarne il comportamento di questo automa con quello per $(L^C_1 \\cup L^C_2)^C$ costruito con le funzioni del punto precedente.\n",
        "\n",
        "* Implementate una funzione per la *minimizzazione* di un DFA, o secondo l'algoritmo presentato nella Sezione 5.7, oppure secondo l'algoritmo di [Brzozowski](https://en.wikipedia.org/wiki/DFA_minimization#Brzozowski's_algorithm)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
